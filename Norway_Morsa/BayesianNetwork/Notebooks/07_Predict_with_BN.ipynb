{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "import bayes_net_utils as bn\n",
    "pd.options.display.width=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian network predictions\n",
    "\n",
    "The R code required to run the Bayesian network and generate predictions has been refactored into the R function `bayes_net_predict` in `bayes_net_utils.R`. There is also a Python function of the same name in `bayes_net_utils.py`, which provides a simple \"wrapper\" around the R fucntion and some minor additional calculations. This should make it easy to make predictions from the Bayesian network via Python.\n",
    "\n",
    "**Note:** There is some computational overhead involved in interfacing between Python and R, but this isn't a major problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User options\n",
    "\n",
    "run_mode = 'Historic'        # Run mode? 'Historic' for period 1981-2018/19, or 'NextSeason' for future (operational, or one historic test season)\n",
    "if run_mode == 'NextSeason': # If making predictions for the next season, for which year? For file reading\n",
    "    target_yr = 2020\n",
    "\n",
    "met_evidence = 'era5'  # Source of met data used to create data for driving predictions? 'metno', 'era5' or 's5'\n",
    "\n",
    "# Use dictionary to automatically set the met data used in network training based on the source of data used to drive predictions.\n",
    "# If met data for predictions is not s5, should be the same as met_evidence. If 's5', should be 'era5' as that was used in bias correcting s5\n",
    "met_training_dict = {'metno':'metno',\n",
    "                    'era5':'era5',\n",
    "                    's5':'era5'}\n",
    "met_training = met_training_dict[met_evidence]\n",
    "\n",
    "# Start and end years of data used to fit network (used in the .rds filepath) and, for Historic run_mode, in generating the data for prediction\n",
    "# (and in the filepaths to these csvs)\n",
    "st_end_yr_dict = {'metno': [1981,2018],\n",
    "               'era5': [1981,2019],\n",
    "               's5': [1993,2019]}\n",
    "\n",
    "# Fitted bnlearn object\n",
    "rfile_fpath = \"../Data/RData/Vansjo_fitted_GaussianBN_%s_%s-%s.rds\" %(met_training, st_end_yr_dict[met_training][0], st_end_yr_dict[met_training][1])\n",
    "\n",
    "# Pre-calculated standard deviations\n",
    "sd_fpath = \"../Data/FittedNetworkDiagnostics/GBN_%s_%s-%s_stdevs.csv\" %(met_training, st_end_yr_dict[met_training][0], st_end_yr_dict[met_training][1])\n",
    "\n",
    "# The 'evidence' (data that will be used to drive the predictions) folder\n",
    "ev_folder = r'../Data/DataForPrediction/%s/%s' %(run_mode, met_evidence)\n",
    "\n",
    "# Outfolder to save predictions in\n",
    "out_folder = r'../Data/Predictions/%s' %run_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict multiple years at once\n",
    "\n",
    "If you are just predicting for one season, you can use bn.bayes_net_predict by itself. The function below works too, but is particularly useful for producing predictions for all years in a historic test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df):\n",
    "    \"\"\"\n",
    "    Loop over rows in evidence dataframe and make predictions for each row (year), and concatenate results into a\n",
    "    single df\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for idx, row in ev_df.iterrows():\n",
    "        # Run Bayesian network in R\n",
    "        df = bn.bayes_net_predict(rfile_fpath,\n",
    "                                  sd_fpath,\n",
    "                                  float(row['year']),\n",
    "                                  float(row['chla_prevSummer']),\n",
    "                                  float(row['colour_prevSummer']),\n",
    "                                  float(row['TP_prevSummer']),\n",
    "                                  float(row['wind_speed']),\n",
    "                                  float(row['rain']),\n",
    "                                 )\n",
    "    #     # Add 'year' to results as unique identifier\n",
    "    #     df['year'] = int(row['year'])\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Merge results from all years\n",
    "    df = pd.concat(df_list, sort=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Re-order cols\n",
    "    df = df[['year', 'node', 'threshold','prob_below_threshold', \n",
    "             'prob_above_threshold', 'expected_value', 'sd','WFD_class']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for 'deterministic' met data (e.g. met.no or ERA5)\n",
    "\n",
    "Where there is just a single 'evidence' datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>node</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prob_below_threshold</th>\n",
       "      <th>prob_above_threshold</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>sd</th>\n",
       "      <th>WFD_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>19.300</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>colour</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>28.800</td>\n",
       "      <td>9.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>cyano</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.090</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>37.000</td>\n",
       "      <td>3.790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.100</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2018</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.200</td>\n",
       "      <td>3.790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.100</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2019</td>\n",
       "      <td>colour</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>42.000</td>\n",
       "      <td>9.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2019</td>\n",
       "      <td>cyano</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>22.600</td>\n",
       "      <td>3.790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    node  threshold  prob_below_threshold  prob_above_threshold  \\\n",
       "0    1981    chla       20.0                  0.57                  0.43   \n",
       "1    1981  colour       48.0                  0.98                  0.02   \n",
       "2    1981   cyano        1.0                  0.23                  0.77   \n",
       "3    1981      TP       29.5                  0.02                  0.98   \n",
       "4    1982    chla       20.0                  0.98                  0.02   \n",
       "..    ...     ...        ...                   ...                   ...   \n",
       "151  2018      TP       29.5                  0.95                  0.05   \n",
       "152  2019    chla       20.0                  0.98                  0.02   \n",
       "153  2019  colour       48.0                  0.75                  0.25   \n",
       "154  2019   cyano        1.0                  0.83                  0.17   \n",
       "155  2019      TP       29.5                  0.97                  0.03   \n",
       "\n",
       "     expected_value     sd  WFD_class  \n",
       "0            19.300  3.760          0  \n",
       "1            28.800  9.040          0  \n",
       "2             2.090  0.719          1  \n",
       "3            37.000  3.790          1  \n",
       "4            11.100  3.760          0  \n",
       "..              ...    ...        ...  \n",
       "151          23.200  3.790          0  \n",
       "152          11.100  3.760          0  \n",
       "153          42.000  9.040          0  \n",
       "154           0.369  0.719          0  \n",
       "155          22.600  3.790          0  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if met_evidence !='s5':\n",
    "    \n",
    "    # Sort out filepaths for the evidence data to read in and the output file\n",
    "    if run_mode == 'NextSeason':\n",
    "        ev_fname = 'DataForPrediction_GBN_%s_%s.csv' %(met_evidence, target_yr)\n",
    "        out_fname = 'GBN_prediction_%s_%s.csv' %(met_evidence, target_yr)\n",
    "    else:\n",
    "        ev_fname = 'DataForPrediction_GBN_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "        out_fname = 'GBN_prediction_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "        \n",
    "    ev_path = os.path.join(ev_folder, ev_fname)\n",
    "    out_path = os.path.join(out_folder, out_fname)\n",
    "    \n",
    "    # Read in evidence and optionally display\n",
    "    ev_df = pd.read_csv(ev_path)\n",
    "    \n",
    "#     display(ev_df.head())\n",
    "    \n",
    "    # Predict and save to csv\n",
    "    df = bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df)\n",
    "    \n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions using evidence derived from seasonal forecast data\n",
    "\n",
    "Where there may be multiple seasons and members. Currently set up for System5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if met_evidence == 's5':\n",
    "    \n",
    "    member_li = [\"%.2d\" % i for i in range(1,26)] # List of S5 member numbers in format '01','02'... Should be present in s5 met data folder\n",
    "    season_li = ['summer','late_summer'] # Seasons of interest (must match filenames in s5 met data folder)\n",
    "\n",
    "    for season in season_li:\n",
    "        for member in member_li:\n",
    "\n",
    "            # Sort out filepaths for the evidence data to read in and the output file\n",
    "            if run_mode == 'NextSeason':\n",
    "                ev_fname = 'DataForPrediction_GBN_%s_%s_%s_%s.csv' %(met_evidence, target_yr, season, member)\n",
    "                out_fname = 'GBN_prediction_%s_%s_%s_%s.csv' %(met_evidence, target_yr, season, member)\n",
    "            else:\n",
    "                ev_fname = 'DataForPrediction_GBN_%s_%s-%s_%s_%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1], season, member)\n",
    "                out_fname = 'GBN_prediction_%s_%s-%s_%s_%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1], season, member)\n",
    "\n",
    "            ev_path = os.path.join(ev_folder, ev_fname)\n",
    "            out_path = os.path.join(out_folder, 's5', out_fname)\n",
    "\n",
    "            # Read in evidence\n",
    "            ev_df = pd.read_csv(ev_path)\n",
    "\n",
    "            # Predict and save to csv\n",
    "            df = bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df)\n",
    "            df.to_csv(out_path, index=False)\n",
    "\n",
    "    # Display output for the last season and member for checking\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest possible model: target season = previous season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>chla</th>\n",
       "      <th>colour</th>\n",
       "      <th>cyano</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>43.573016</td>\n",
       "      <td>16.080130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>28.833333</td>\n",
       "      <td>8.331250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>26.988095</td>\n",
       "      <td>5.975000</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>29.781250</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>17.625000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>26.527500</td>\n",
       "      <td>11.090000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>30.957143</td>\n",
       "      <td>11.895238</td>\n",
       "      <td>34.404762</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>33.788889</td>\n",
       "      <td>12.677778</td>\n",
       "      <td>27.472222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>23.433333</td>\n",
       "      <td>8.511111</td>\n",
       "      <td>29.027778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>29.533333</td>\n",
       "      <td>14.055556</td>\n",
       "      <td>32.277778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>27.057143</td>\n",
       "      <td>14.271429</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>28.900000</td>\n",
       "      <td>12.242857</td>\n",
       "      <td>19.857143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>27.225000</td>\n",
       "      <td>9.425000</td>\n",
       "      <td>20.625000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>31.342857</td>\n",
       "      <td>16.757143</td>\n",
       "      <td>21.285714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>27.300000</td>\n",
       "      <td>12.614286</td>\n",
       "      <td>24.428571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>30.442857</td>\n",
       "      <td>18.257143</td>\n",
       "      <td>27.714286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>29.450000</td>\n",
       "      <td>21.883333</td>\n",
       "      <td>25.833333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>31.283333</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>4.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>29.416667</td>\n",
       "      <td>23.066667</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>32.366667</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.423077</td>\n",
       "      <td>5.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>32.666667</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>42.560000</td>\n",
       "      <td>4.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>38.333333</td>\n",
       "      <td>21.033333</td>\n",
       "      <td>68.423077</td>\n",
       "      <td>0.5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>36.666667</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>54.576923</td>\n",
       "      <td>0.9820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>33.571429</td>\n",
       "      <td>16.821429</td>\n",
       "      <td>42.875000</td>\n",
       "      <td>1.2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>36.833333</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>5.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>32.010870</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>3.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>34.500000</td>\n",
       "      <td>29.154167</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>4.5602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>32.160000</td>\n",
       "      <td>17.944000</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>3.5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>32.750000</td>\n",
       "      <td>15.887500</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>28.956522</td>\n",
       "      <td>16.343478</td>\n",
       "      <td>58.285714</td>\n",
       "      <td>1.5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>26.347826</td>\n",
       "      <td>11.695652</td>\n",
       "      <td>61.714286</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>26.560000</td>\n",
       "      <td>12.188000</td>\n",
       "      <td>72.888889</td>\n",
       "      <td>0.0790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>26.391304</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>64.153846</td>\n",
       "      <td>0.2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>22.992308</td>\n",
       "      <td>14.138462</td>\n",
       "      <td>60.223077</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>20.300000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>41.863636</td>\n",
       "      <td>0.2830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>24.250000</td>\n",
       "      <td>14.925000</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>0.2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>18.750000</td>\n",
       "      <td>9.590909</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>19.666667</td>\n",
       "      <td>12.866667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>18.666667</td>\n",
       "      <td>10.741667</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>0.6140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TP       chla     colour   cyano\n",
       "year                                         \n",
       "1981  43.573016  16.080130        NaN     NaN\n",
       "1982  28.833333   8.331250        NaN     NaN\n",
       "1983  26.988095   5.975000  26.666667     NaN\n",
       "1984  29.781250   6.050000  17.625000     NaN\n",
       "1985  26.527500  11.090000        NaN     NaN\n",
       "1986  30.957143  11.895238  34.404762     NaN\n",
       "1987  33.788889  12.677778  27.472222     NaN\n",
       "1988  23.433333   8.511111  29.027778     NaN\n",
       "1989  29.533333  14.055556  32.277778     NaN\n",
       "1990  27.057143  14.271429  23.857143     NaN\n",
       "1991  28.900000  12.242857  19.857143     NaN\n",
       "1992  27.225000   9.425000  20.625000     NaN\n",
       "1993  31.342857  16.757143  21.285714     NaN\n",
       "1994  27.300000  12.614286  24.428571     NaN\n",
       "1995  30.442857  18.257143  27.714286     NaN\n",
       "1996  29.450000  21.883333  25.833333     NaN\n",
       "1997  31.283333  21.300000  17.666667  4.8000\n",
       "1998  29.416667  23.066667  19.000000  2.8200\n",
       "1999  32.366667  21.100000        NaN  2.2800\n",
       "2000        NaN        NaN  50.423077  5.9600\n",
       "2001  32.666667  22.166667  42.560000  4.6700\n",
       "2002  38.333333  21.033333  68.423077  0.5800\n",
       "2003  36.666667  25.500000  54.576923  0.9820\n",
       "2004  33.571429  16.821429  42.875000  1.2910\n",
       "2005  36.833333  25.600000  38.666667  5.2600\n",
       "2006  32.010870  20.200000  46.500000  3.0626\n",
       "2007  34.500000  29.154167  48.333333  4.5602\n",
       "2008  32.160000  17.944000  64.666667  3.5880\n",
       "2009  32.750000  15.887500  69.000000  0.7390\n",
       "2010  28.956522  16.343478  58.285714  1.5860\n",
       "2011  26.347826  11.695652  61.714286  0.2240\n",
       "2012  26.560000  12.188000  72.888889  0.0790\n",
       "2013  26.391304  13.800000  64.153846  0.2110\n",
       "2014  22.992308  14.138462  60.223077  0.5340\n",
       "2015  20.300000  12.600000  41.863636  0.2830\n",
       "2016  24.250000  14.925000  52.833333  0.2330\n",
       "2017  18.750000   9.590909  52.000000  0.1660\n",
       "2018  19.666667  12.866667  42.000000  0.2580\n",
       "2019  18.666667  10.741667  36.333333  0.6140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_fpath = '../Data/DataMatrices/Seasonal_BN_obs/seasonal_obs_GBN_1980-2019.csv'\n",
    "\n",
    "# Read in evidence and optionally display\n",
    "obs_df = pd.read_csv(obs_fpath, index_col=0)\n",
    "# display(obs_df.head())\n",
    "\n",
    "# Fill NaNs in water chemistry and ecology (linearly interpolate and backwards fill)\n",
    "# obs_df.interpolate(method='linear',limit=1, inplace=True)\n",
    "\n",
    "# Predict and save to csv\n",
    "sim_df = obs_df.shift(+1).loc[1981:]\n",
    "\n",
    "# Save to csv\n",
    "if run_mode == 'NextSeason':\n",
    "    out_fname = 'Prediction_naive_%s.csv' %(target_yr)\n",
    "else:\n",
    "    out_fname = 'Prediction_naive_%s-%s.csv' %(st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "out_path = os.path.join(out_folder, out_fname)\n",
    "\n",
    "sim_df.to_csv(out_path)\n",
    "\n",
    "display(sim_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
